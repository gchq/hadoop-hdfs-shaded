buildscript {
    repositories {
        mavenLocal()
        jcenter()
    }
}

plugins {
    id 'com.github.johnrengelman.shadow' version '2.0.3' apply true
    id "com.jfrog.bintray" version "1.7.3" apply true
}

task wrapper(type: Wrapper) {
    gradleVersion = '4.6'
}

//if the project has a value for the passed property (i.e from the cmd line via -PpropName=xxx)
//use that, else use a default value
ext.getPropertyOrDefault = { propName, defaultValue -> 
    def val;
    if (project.hasProperty(propName) && project.getProperty(propName) != "unspecified" && project.getProperty(propName) != "") {
        val = project.getProperty(propName)
        println "Using property [$propName] with value [$val]"
    } else {
        val = defaultValue
        println "Property [$propName] has no value, using default value [$val]"
    }
    return val;
}

ext.versions = [
    //------hadoop-hdfs-shaded-------
    hadoopHdfsShaded: getPropertyOrDefault('version', 'SNAPSHOT'),

    //------3rd party libs------------
    hadoop: '2.6.4',
    zzzDummyzzz: 'Here to make sorting easier'
]

//dependency strings for use in sub projects
ext.libs = [
    hadoop_hdfs: "org.apache.hadoop:hadoop-hdfs:$versions.hadoop",
    zzzDummyzzz: 'Here to make sorting easier'
]

apply plugin: 'idea'
apply plugin: 'java'
apply plugin: 'maven'
apply plugin: 'maven-publish'

repositories {
    mavenLocal()
    jcenter()
}

dependencies {
    compile(libs.hadoop_hdfs) {
        //exclude(module: 'slf4j-api')
        //exclude(module: 'slf4j-log4j12')
        //exclude(module: 'log4j')
        //exclude(module: 'commons-logging:commons-logging')
        // Exclude all logging so we can use our own SLF4J/Logback and its bridging pkgs
        exclude group: "org.slf4j", module: "slf4j-api"
        exclude group: "org.slf4j", module: "slf4j-log4j12"
        exclude group: "log4j", module: "log4j"
        exclude group: "commons-logging", module: "commons-logging"

        // We want to use the xerces impl bundled in the jdk
        // see https://stackoverflow.com/questions/11677572/dealing-with-xerces-hell-in-java-maven
        exclude module: 'xercesImpl'
    }
}

group = 'stroom'
version = versions.hadoopHdfsShaded

sourceCompatibility = 1.8
targetCompatibility = 1.8


//task sourceJar(type: Jar){
    //from sourceSets.main.allJava
    //classifier 'sources'
//}

def pomConfig = {
    licenses {
        license {
            name "The Apache Software License, Version 2.0"
            url "http://www.apache.org/licenses/LICENSE-2.0.txt"
            distribution "repo"
        }
    }
    scm {
       url "https://github.com/stroom/hadoop-hdfs-shaded"
    }
}

publishing {
    publications {
        //mavenJava(MavenPublication) {
            //from components.java
        //}
        //shadow(MavenPublication) {
            //from components.shadow
        //}
        shadow(MavenPublication) { publication ->
            project.shadow.component(publication)
            // No point in publishing sources/javadocs as these will be empty as the
            // shadow plugin cannot merge dependency sources/javadocs into shadow jars
            //artifact sourcesJar
            //artifact javadocJar
            pom.withXml {
                def root = asNode()
                root.appendNode('name', project.name)
                root.children().last() + pomConfig
            }
        }
    }
}

//configuration for the bintray plugin for uploading maven artefacts to bintray
//see https://github.com/bintray/gradle-bintray-plugin
//run task bintrayUpload to push the files, assuming BINTRAY_USER/KEY are set as env vars
bintray {
    //Must never write these to log or system out
    user = System.getenv('BINTRAY_USER') //set in Travis UI
    key = System.getenv('BINTRAY_KEY') //set in Travis UI

    //The maven plugin publications to push to bintray
    publications = ['shadow']

    //immediately make the artefacts public
    publish = true

    pkg {
        repo = 'stroom'
        name = 'hadoop-hdfs-shaded'
        userOrg = 'stroom'
        licenses = ['Apache-2.0'] //This assume the only 
        vcsUrl = 'https://github.com/gchq/hadoop-hdfs-shaded.git'
        version {
            name = "${versions.hadoopHdfsShaded}"
            desc = "hadoop-hdfs-shaded-${versions.hadoopHdfsShaded}"
            released  = new Date()
            vcsTag = "${versions.hadoopHdfsShaded}"
            gpg {
                //Bintray will self-sign the files
                sign = true //Determines whether to GPG sign the files. The default is false
            }
        }
    }
}

//shadowJar {
    //relocate 'com.sun.jersey', 'shaded.com.sun.jersey'
    //relocate 'javax.ws.rs', 'shaded.javax.ws.rs'
    //relocate 'javax.el', 'shaded.javax.el'
    //relocate 'javax.servlet', 'shaded.javax.servlet'
    //relocate 'com.google.common', 'shaded.com.google.common'
//}

shadowJar {
    //this stops the maven classifier being 'all'. We want the default jar to be the shadow one
    classifier = ''
    def prefix = "stroom.hadoophdfsshaded." 

    // relocate package pkg, with a list of exclsuions
    // exclusions are like 'javax/security/**'
    def relocatePackageWithExclusions = { String pkg, List<String> exclusions ->
        relocate (pkg, prefix + pkg) {
            if (exclusions != null) {
                exclusions.each { 
                    exclude it
                }
            }
        }
    }

    // method for doing the relocation of a package
    def relocatePackage = { String pkg -> 
        relocatePackageWithExclusions(pkg, [])
    }

    // rename all non hadoop packages to avoid conflicts
    // you can use the following to find the unique packages in the shadow jar
    // unzip -t hadoop-hdfs-shaded-SNAPSHOT.jar | sed -r 's#.*: (((\w+)\/)+).*OK#\1#g' | sed 's#.*META-INF.*##g' | uniq | grep -v hadoophdfsshaded
    relocatePackage 'com.google'
    relocatePackage 'com.sun.jersey'
    relocatePackage 'com.sun.research'
    relocatePackage 'javax.annotation'
    relocatePackage 'javax.el'
    relocatePackage 'javax.servlet'
    relocatePackage 'javax.ws'
    relocatePackageWithExclusions 'org', [
        'org/apache/commons/logging/**', 
        'org/apache/hadoop/**',
        'org/w3c/dom/**',
        'org/xml/**',
        'org/slf4j/**']
}

tasks.build.dependsOn shadowJar
